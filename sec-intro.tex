\section{Introduction}
\emph{Instance matching} \cite{DBLP:journals/ijswis/FerraraNS11} refers to the problem of determining whether two descriptions are about the same real-world entity. Traditionally, research in this context was focused on the single-domain setting, where data come from the \emph{same or similar datasets}. Basically, given the descriptions of entities available as records in databases, RDF descriptions on the Web, etc., the instance matching task breaks down to the core problems of (1) finding a suitable \emph{instance representation} (i.e., selecting attributes and their values), (2) using this for evaluating different \emph{similarity measures}, and (3) finally selecting the most similar ones according to a \emph{threshold}. 
%To sum up, the instance matching problem lays on efficiently finding candidate matches and effectively assigning the correct matches. 

For large datasets, the instance matching problem is typically solved in two steps, namely to find candidate matches first using a relatively simple but quick matching technique, and then to refine them using a more advanced but also more expensive technique. For the latter more sophisticated and \emph{effective matching}, there are different techniques for learning the right combination of attributes, similarity measures and threshold to be used for computing and selecting the resulting matches~\cite{DBLP:conf/cikm/SongH10,MaurouxHJAM09,nikolov08}. Typically, the former, \emph{candidate selection} resembles what is called  \emph{blocking}~\cite{hernandez_merge/purge_1995,MichelsonK06,elmagarmid_duplicate_2007} in the single dataset settings (e.g. deduplication), which is described as the process of finding non-overlapping blocks of instances that share a similar key (a compact description of an instance), such that they can be compared between each other. For this type of key matching, indexes can be built to accelerate the process. In particular, fast \emph{index lookups} can be performed to directly retrieve candidates from the index that share/overlap with the key of a given source instance. 

%For instance, given an instance and the value tokens \verb+Anemia+ appearing in its \verb+name+ attribute as key, candidates for this instance can be obtained via an index lookup, which simply returns all instances with \verb+Anemia+ as name. 
%Given two datasets with $n$ and $m$ elements respectively, candidate selection requires only $n$ lookup queries over the index built for the $m$ elements (for retrieving candidate blocks for $n$ elements), while $n\times m$ similarity computation steps are needed for the effective matching of instances between these datasets. 

In this work, we focus on the problem of candidate selection in the Web environment with \emph{multiple heterogeneous datasets}, such as Linked Data. Here, heterogeneity particularly means that the datasets' schemas might vary. Existing techniques~\cite{MichelsonK06} assume instances are from the same or similar datasets such that the keys chose for one dataset can also be used to find candidates in the other datasets. This is however problematic in this setting because for a key such as one based on the values of the \verb+name+ attribute in the one dataset, there might not exist the \verb+name+ attribute, in the other datasets. Aiming to address this problem of heterogeneity, schema-agnostic candidate selection has been proposed recently~\cite{papadakis_efficient_2011}. It does not exploit attributes for building keys, but instead, simply treat instances as unstructured bags of tokens that can be extracted from the attribute values. That is, the key is simply composed of set of tokens that do not come with any attribute information. Instances are considered similar and form blocks when their keys overlap, i.e. they have some tokens in common. The drawback of the schema-agnostic approach is that it may build very ambiguous candidate sets, because a token may not be discriminative enough. For instance, the token "Paris", occurs 147.515 times at DBPedia\footnote{http://dbpedia.org/} dataset. 
%We illustrate the heterogeneity problem and the drawbacks of the schema-agnostic approach to that using the following example: 

%\begin{example}
%There are two descriptions of the \verb+anemia+ disease that were extracted from two different datasets. The first one is the Diseasome dataset, which specifically represents data from the Life Science domain. The second one is DBpedia, a cross-domain encyclopedic type of dataset.  
%While the description from Diseasome describes genetic aspects (Fig. 1, line 1), the one from DBpedia captures general aspects (Fig. 1, line 7) of \verb+anemia+. The only token they have in common is ``Anemia'', while their schemas do not overlap at all. Applying blocking techniques that use attributes to form keys~\cite{DBLP:conf/semweb/SongH11} is not directly possible because there are no common attributes shared by these datasets. Using schema-agnostic blocking that compares instances simply by value tokens, these instances can be identified to be candidate matches. However, this token match is not enough to guarantee these instances refer to the same disease, because this blocking may yield other candidates, such as \verb+anemia+ as a plant, as shown in Fig. 1, line 12. 
%\end{example}

%\begin{figure} 
 
%\centering
%\includegraphics[width=0.8\textwidth]{fig1.png}
%\caption{Examples for ``Anemia'' in N3 notation (prefixes are used for brevity).} 
%\vspace{-10pt}
%\end{figure} 

We note that there exist only a few works~\cite{DBLP:conf/semweb/SongH11,papadakis_efficient_2011} that specifically address the problem of candidate selection over multiple heterogeneous datasets. To this end, this work provides the following contributions: 

\textbf{Effective Candidate Selection}. Schema-agnostic candidate selection looses valuable attribute information and thus may yield too many candidates. On the other hand, using attributes to form keys requires schema matching\cite{DBLP:conf/ic3k/ScharffeE11} to find attributes in one dataset that correspond to (key) attributes in the other dataset~\cite{DBLP:conf/semweb/SongH11}. 
%As illustrated by the example, attribute matches between datasets may not exist. 
In this work, we exploit attribute information for more effective blocking. However, we do not require attributes to complete match (e.g. "surname" and "family name") but employ a more relaxed notion of \emph{comparability} (e.g. we may map "drugname" and "synomym"). In particular, even when they represent completely different attributes, some pairs of attributes among them might be more comparable than some other pairs. The comparability between attributes is then used to construct lookup queries on the target dataset. In order to obtain a high recall (i.e. retain correct candidates, true positives), which is the topmost goal in candidate selection, all comparable attributes have to be considered for constructing the queries. Among them, there exists a group that return the best set of candidates. We propose a \emph{branch-and-bound based optimization framework} that iteratively search for this optimal query. 

\textbf{Efficient Candidate Selection}. 
%We also show that schema-agnostic candidate selection is not efficient as queries built from values without attribute information. They match a large number of instances, resulting in a large amount of data that has to be loaded from disk. 
Using attribute-value pairs in the keys increases the selectivity of the resulting queries. However, since all comparable attributes are considered for achieving high recall, we obtain a large amount of candidate queries. To also optimize for efficiency, we incorporate the number of queries and query execution times into the branch-and-bound optimization so that it is geared not only towards queries that produce high quality results but also, towards executing a minimal number of time-efficient queries. 

In the experiments, we show that compared to the schema-agnostic~\cite{papadakis_efficient_2011} and the schema-based~\cite{DBLP:conf/semweb/SongH11} baselines, our approach yields superior results both in terms of efficiency and effectiveness in 96\% of the cases. 

\textbf{Outline.} 
This paper is organized as follows. After this introduction, we present the problem of candidate selection over multiple heterogeneous datasets, in the Section 2. In Section 3, we elaborate on our algorithm for building candidate selection queries. In Section 4, we present the algorithm to find candidate sets itself.  Section 5 presents the experimental results, along with a comparative study against two known state-of-the-art approaches for candidate selection. Section 6 introduces the related work. Finally, Section 7 concludes this paper.
